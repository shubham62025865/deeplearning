{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham62025865/deeplearning/blob/main/Word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec\n",
        "\n",
        "Word2Vec creates vectors of the words that are distributed numerical representations of word features – these word features could comprise of words that represent the context of the individual words present in our vocabulary. Word embeddings eventually help in establishing the association of a word with another similar meaning word through the created vectors.\n",
        "\n",
        "As seen in the image below where word embeddings are plotted, similar meaning words are closer in space, indicating their semantic similarity.\n",
        "\n",
        "<img src = https://editor.analyticsvidhya.com/uploads/93033pic1.png >\n",
        "\n"
      ],
      "metadata": {
        "id": "LXZFzor4yM7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec Architecture\n",
        "\n",
        "The effectiveness of Word2Vec comes from its ability to group together vectors of similar words. Given a large enough dataset, Word2Vec can make strong estimates about a word’s meaning based on their occurrences in the text. These estimates yield word associations with other words in the corpus. For example, words like “King” and “Queen” would be very similar to one another. When conducting algebraic operations on word embeddings you can find a close approximation of word similarities. For example, the 2 dimensional embedding vector of \"king\" - the 2 dimensional embedding vector of \"man\" + the 2 dimensional embedding vector of \"woman\" yielded a vector which is very close to the embedding vector of \"queen\". Note, that the values below were chosen arbitrarily.\n",
        "```\n",
        "King    -    Man    +    Woman    =    Queen\n",
        "[5,3]   -    [2,1]  +    [3, 2]   =    [6,4]  \n",
        "```\n",
        "\n",
        "<img src = https://miro.medium.com/max/720/1*hnu-NqrK3C7wmYWcKXpb-Q.webp >"
      ],
      "metadata": {
        "id": "kJPDZADPzE33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two main architectures which yield the success of word2vec. The skip-gram and CBOW architectures."
      ],
      "metadata": {
        "id": "RCSwAX0LzbG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CBOW (Continuous Bag of Words)\n",
        "This architecture is very similar to a feed forward neural network. This model architecture essentially tries to predict a target word from a list of context words. The intuition behind this model is quite simple: given a phrase \"Have a great day\" , we will choose our target word to be “a” and our context words to be [“have”, “great”, “day”]. What this model will do is take the distributed representations of the context words to try and predict the target word.\n",
        "\n",
        "<img src = https://miro.medium.com/max/640/1*_8Ul4ICaCtmZWPrWqH32Ow.webp >"
      ],
      "metadata": {
        "id": "FmVuB7o4zcTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Continuous Skip-Gram Model\n",
        "The skip-gram model is a simple neural network with one hidden layer trained in order to predict the probability of a given word being present when an input word is present. Intuitively, you can imagine the skip-gram model being the opposite of the CBOW model. In this architecture, it takes the current word as an input and tries to accurately predict the words before and after this current word. This model essentially tries to learn and predict the context words around the specified input word. Based on experiments assessing the accuracy of this model it was found that the prediction quality improves given a large range of word vectors, however it also increases the computational complexity. The process can be described visually as seen below.\n",
        "\n",
        "<img src = https://miro.medium.com/max/828/1*M6UxaLSbNMeoDFWRN_kPeQ.webp >\n",
        "\n",
        "\n",
        "As seen above, given some corpus of text, a target word is selected over some rolling window. The training data consists of pairwise combinations of that target word and all other words in the window. This is the resulting training data for the neural network. Once the model is trained, we can essentially yield a probability of a word being a context word for a given target. The following image below represents the architecture of the neural network for the skip-gram model.\n",
        "\n",
        "<img src = https://miro.medium.com/max/828/1*UYAkOS9JQwdozQjCzttuow.webp >\n",
        "\n",
        "A corpus can be represented as a vector of size N, where each element in N corresponds to a word in the corpus. During the training process, we have a pair of target and context words, the input array will have 0 in all elements except for the target word. The target word will be equal to 1. The hidden layer will learn the embedding representation of each word, yielding a d-dimensional embedding space. The output layer is a dense layer with a softmax activation function. The output layer will essentially yield a vector of the same size as the input, each element in the vector will consist of a probability. This probability indicates the similarity between the target word and the associated word in the corpus."
      ],
      "metadata": {
        "id": "rpv1L1B_z2a6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYLC3xcdMKHw",
        "outputId": "f371c3d3-37e3-4a8d-edb4-898983b1f566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gensim\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from nltk import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import remove_stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEBkUuJiMXJ6",
        "outputId": "d64b01e0-711f-49d3-8898-6922f0ab1ad9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = '''\n",
        "Shiva looked up at the Pandit, his eyes full of surprise and shame.\n",
        "\n",
        "‘I know what you have done, Oh Neelkanth,’said the Pandit. ‘And I ask again, is it really so\n",
        "bad?’\n",
        "\n",
        "‘Don’t call me the Neelkanth,’ glared Shiva. ‘I don’t deserve the tide. I have the blood of\n",
        "thousands on my hands.’\n",
        "\n",
        "‘Many more than thousands have died,’said the Pandit. ‘Probably hundreds of thousands. But\n",
        "you really think they wouldn’t have died if you hadn’t been around? Is the blood really on your\n",
        "hands?’\n",
        "'''\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "ycRZgdBPuSt1",
        "outputId": "e5ab0cf3-4001-4da2-b07a-30ba09259aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nShiva looked up at the Pandit, his eyes full of surprise and shame.\\n\\n‘I know what you have done, Oh Neelkanth,’said the Pandit. ‘And I ask again, is it really so\\nbad?’\\n\\n‘Don’t call me the Neelkanth,’ glared Shiva. ‘I don’t deserve the tide. I have the blood of\\nthousands on my hands.’\\n\\n‘Many more than thousands have died,’said the Pandit. ‘Probably hundreds of thousands. But\\nyou really think they wouldn’t have died if you hadn’t been around? Is the blood really on your\\nhands?’\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence tokenisation\n",
        "# stop word removal\n",
        "# punctuations\n",
        "# lower case\n",
        "# lemmatization\n",
        "\n"
      ],
      "metadata": {
        "id": "kmmzDJ-Ku3sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = sent_tokenize(sample)"
      ],
      "metadata": {
        "id": "7N_s58Up4iZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDKfc7e34iVj",
        "outputId": "69456e2b-0ab8-4779-c86b-0e7a0807b371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nShiva looked up at the Pandit, his eyes full of surprise and shame.',\n",
              " '‘I know what you have done, Oh Neelkanth,’said the Pandit.',\n",
              " '‘And I ask again, is it really so\\nbad?’\\n\\n‘Don’t call me the Neelkanth,’ glared Shiva.',\n",
              " '‘I don’t deserve the tide.',\n",
              " 'I have the blood of\\nthousands on my hands.’\\n\\n‘Many more than thousands have died,’said the Pandit.',\n",
              " '‘Probably hundreds of thousands.',\n",
              " 'But\\nyou really think they wouldn’t have died if you hadn’t been around?',\n",
              " 'Is the blood really on your\\nhands?’']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs = [remove_stopwords(token) for token in tokens]\n",
        "rs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KTAEA3K-fiU",
        "outputId": "20d1225f-6f6b-47c2-ed88-38e2bffc6b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Shiva looked Pandit, eyes surprise shame.',\n",
              " '‘I know done, Oh Neelkanth,’said Pandit.',\n",
              " '‘And I ask again, bad?’ ‘Don’t Neelkanth,’ glared Shiva.',\n",
              " '‘I don’t deserve tide.',\n",
              " 'I blood thousands hands.’ ‘Many thousands died,’said Pandit.',\n",
              " '‘Probably hundreds thousands.',\n",
              " 'But think wouldn’t died hadn’t around?',\n",
              " 'Is blood hands?’']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp = [simple_preprocess(sentence) for sentence in rs]\n",
        "sp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkoeiJIw_ApJ",
        "outputId": "7f8bc3ff-e4e5-4146-947d-51328d32b159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['shiva', 'looked', 'pandit', 'eyes', 'surprise', 'shame'],\n",
              " ['know', 'done', 'oh', 'neelkanth', 'said', 'pandit'],\n",
              " ['and', 'ask', 'again', 'bad', 'don', 'neelkanth', 'glared', 'shiva'],\n",
              " ['don', 'deserve', 'tide'],\n",
              " ['blood',\n",
              "  'thousands',\n",
              "  'hands',\n",
              "  'many',\n",
              "  'thousands',\n",
              "  'died',\n",
              "  'said',\n",
              "  'pandit'],\n",
              " ['probably', 'hundreds', 'thousands'],\n",
              " ['but', 'think', 'wouldn', 'died', 'hadn', 'around'],\n",
              " ['is', 'blood', 'hands']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[[lemma.lemmatize(word) for word in sentence] for sentence in sp]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v83SEzbJ_8Vu",
        "outputId": "15d08081-ce5c-4e73-e918-dbec1234f942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['shiva', 'looked', 'pandit', 'eye', 'surprise', 'shame'],\n",
              " ['know', 'done', 'oh', 'neelkanth', 'said', 'pandit'],\n",
              " ['and', 'ask', 'again', 'bad', 'don', 'neelkanth', 'glared', 'shiva'],\n",
              " ['don', 'deserve', 'tide'],\n",
              " ['blood', 'thousand', 'hand', 'many', 'thousand', 'died', 'said', 'pandit'],\n",
              " ['probably', 'hundred', 'thousand'],\n",
              " ['but', 'think', 'wouldn', 'died', 'hadn', 'around'],\n",
              " ['is', 'blood', 'hand']]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dqv_NEh2wdw4",
        "outputId": "0a334ee6-dc9c-422c-a478-6fc1a01645cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'But\\nyou really think they wouldn’t have died if you hadn’t been around?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs = remove_stopwords(tokens[6])\n",
        "rs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4mrTQyo67VO7",
        "outputId": "0137c055-e8fd-4586-9916-341b60ef2ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'But think wouldn’t died hadn’t around?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp = simple_preprocess(rs)\n",
        "sp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUqYVGRK6GbK",
        "outputId": "7a38bc55-8894-47dc-fa5e-b659fecbf306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['but', 'think', 'wouldn', 'died', 'hadn', 'around']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahybUssa6GLN",
        "outputId": "b4a29f30-9faf-4b2d-935c-171467d41810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "but\n",
            "think\n",
            "wouldn\n",
            "died\n",
            "hadn\n",
            "around\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8VnfeH4Uu3GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemma = WordNetLemmatizer()\n",
        "# shiva = []\n",
        "\n",
        "# open txt file with python\n",
        "\n",
        "with open(\"/content/shiva_01.txt\") as f:\n",
        "  corpus = f.read()\n",
        "  # sentence level tokenization\n",
        "  tokens = sent_tokenize(corpus)\n",
        "\n",
        "  # stop_words removal\n",
        "  rs = [remove_stopwords(token) for token in tokens]\n",
        "\n",
        "  # simple preprocess\n",
        "  sp = [simple_preprocess(sentence) for sentence in rs]\n",
        "\n",
        "  # lemmatization\n",
        "  shiva = [[lemma.lemmatize(word) for word in sentence] for sentence in sp]"
      ],
      "metadata": {
        "id": "Nh9R2URH9RGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shiva"
      ],
      "metadata": {
        "id": "cJeOYIrs9Q_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JT4BRgVf9Q3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bG9pZ09r9Qvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2eLg6Kkw9Qoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "giR9Bmym9QhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shiva = []\n",
        "\n",
        "with open(\"/content/shiva_01.txt\") as f:\n",
        "  corpus = f.read()\n",
        "  tokens = sent_tokenize(corpus)\n",
        "  for token in tokens:\n",
        "    rs = remove_stopwords(token)\n",
        "    sp = simple_preprocess(rs)\n",
        "    shiva.append(sp)"
      ],
      "metadata": {
        "id": "vmv65gO_x5gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shiva"
      ],
      "metadata": {
        "id": "RPbdt5b0y3jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "0Vh6tU1Fs-jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://radimrehurek.com/gensim/parsing/preprocessing.html#\n",
        "\n",
        "https://radimrehurek.com/gensim/utils.html"
      ],
      "metadata": {
        "id": "QGXCgRGhWfkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shiva[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqHvbd24Bnn1",
        "outputId": "e2797e91-2deb-4342-dcca-a5c0e4ce03ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['chapter', 'he', 'come'],\n",
              " ['bc',\n",
              "  'mansarovar',\n",
              "  'lake',\n",
              "  'at',\n",
              "  'foot',\n",
              "  'mount',\n",
              "  'kailash',\n",
              "  'tibet',\n",
              "  'shiva',\n",
              "  'gazed',\n",
              "  'orange',\n",
              "  'sky'],\n",
              " ['the',\n",
              "  'cloud',\n",
              "  'hovering',\n",
              "  'mansarovar',\n",
              "  'parted',\n",
              "  'reveal',\n",
              "  'setting',\n",
              "  'sun'],\n",
              " ['the', 'brilliant', 'giver', 'life', 'calling', 'day', 'again'],\n",
              " ['shiva', 'seen', 'sunrise', 'twenty', 'one', 'year']]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1,2,3],[4,5,6],[],[7,8,9],[]]"
      ],
      "metadata": {
        "id": "p1JmsPXv2eyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count =0\n",
        "for x in a:\n",
        "  if len(x) == 0:\n",
        "    count+=1\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2HhqP_02pHF",
        "outputId": "9f784822-e808-412e-fe60-ba06cdcc99d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(shiva)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czzDRIH3_f1_",
        "outputId": "def99e77-2e58-48c4-e3ca-9cb9506674df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7901"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for x in shiva:\n",
        "  if len(x) ==0:\n",
        "    count+=1\n",
        "\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5TFryuMWg2I",
        "outputId": "77c1a1eb-3083-4955-9506-be07362957bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://radimrehurek.com/gensim/models/word2vec.html"
      ],
      "metadata": {
        "id": "QIxr9F8JArk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(\n",
        "    window=10,\n",
        "    min_count=3\n",
        ")"
      ],
      "metadata": {
        "id": "eeIj5o7Heb1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters:\n",
        "\n",
        "- window: The number of words before the target and after the target word.\n",
        "- min_count: The minimum number of words a sentence should have for it to be part of training."
      ],
      "metadata": {
        "id": "Fs0fRAvpvKMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(shiva)"
      ],
      "metadata": {
        "id": "O8nshjU6mQdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.corpus_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym17jyFOD8Pf",
        "outputId": "7ca8f51b-d192-4c42-bfaf-faddcbb54fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7901"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(shiva, total_examples=model.corpus_count, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HTElBQpmTkD",
        "outputId": "882c5def-5c91-4cbe-f183-5e3677776e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(899037, 1121920)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.corpus_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb_cmIHomi5H",
        "outputId": "bfaefb84-49a0-4166-90c1-13a67b6d8c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7901"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.wv.most_similar('<word>')\n",
        "\n",
        "This method allows to find top 10 most similar words to the word that is passed to the model."
      ],
      "metadata": {
        "id": "xHx0x2CQvwH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('shiva')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rNe9uJtmok2",
        "outputId": "b6cb7801-e3b9-43ef-849a-e2053e1835f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sati', 0.9506832361221313),\n",
              " ('ayurvati', 0.9458413124084473),\n",
              " ('parvateshwar', 0.9420881271362305),\n",
              " ('pandit', 0.9318587183952332),\n",
              " ('brahaspati', 0.9285432696342468),\n",
              " ('krittika', 0.9249944686889648),\n",
              " ('daksha', 0.9151716232299805),\n",
              " ('surprised', 0.9114599823951721),\n",
              " ('smile', 0.9104136824607849),\n",
              " ('bhadra', 0.9091978669166565)]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('sword')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SCu-agumyMO",
        "outputId": "1641dbd7-d871-4ca0-db3d-9e63528231b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('knife', 0.9774574041366577),\n",
              " ('shield', 0.975297749042511),\n",
              " ('moved', 0.9733710885047913),\n",
              " ('brought', 0.9623579978942871),\n",
              " ('side', 0.9613814949989319),\n",
              " ('left', 0.9572250247001648),\n",
              " ('drew', 0.953218936920166),\n",
              " ('distance', 0.9529476761817932),\n",
              " ('arm', 0.9493415355682373),\n",
              " ('reached', 0.9475962519645691)]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('saraswati')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2EOwWVKt8G9",
        "outputId": "1ffb3db0-0c32-4816-b4d7-a33be62b59ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('water', 0.9891326427459717),\n",
              " ('karachapa', 0.9859890937805176),\n",
              " ('narmada', 0.9856348037719727),\n",
              " ('led', 0.9841127991676331),\n",
              " ('equal', 0.9833917617797852),\n",
              " ('indus', 0.9829319715499878),\n",
              " ('one', 0.9820099472999573),\n",
              " ('surrounding', 0.979999840259552),\n",
              " ('extravagantly', 0.9796984791755676),\n",
              " ('south', 0.9796000719070435)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('bhagirath')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpvpS4zAnmBx",
        "outputId": "315965b3-0229-4001-c277-d50d52af6419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('beamed', 0.9950608015060425),\n",
              " ('confused', 0.9950509071350098),\n",
              " ('supported', 0.9949643611907959),\n",
              " ('concern', 0.9946037530899048),\n",
              " ('while', 0.9945772886276245),\n",
              " ('guilt', 0.9945439100265503),\n",
              " ('agnibaan', 0.9945375919342041),\n",
              " ('caused', 0.9944381713867188),\n",
              " ('keeper', 0.9943970441818237),\n",
              " ('implication', 0.9941989779472351)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar('meluha')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obv1HOySnp6T",
        "outputId": "eb1b6277-437a-43bf-bfd7-1cd87e8b0d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('society', 0.9830188155174255),\n",
              " ('people', 0.9788488149642944),\n",
              " ('person', 0.9786986708641052),\n",
              " ('believe', 0.9759514927864075),\n",
              " ('and', 0.973882794380188),\n",
              " ('life', 0.9695990085601807),\n",
              " ('somras', 0.9686427116394043),\n",
              " ('u', 0.9628500938415527),\n",
              " ('way', 0.9627066850662231),\n",
              " ('country', 0.9612454175949097)]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.wv.doesnt_match([array of words])\n",
        "\n",
        "This method allows to find the word that is the least similar to other words that are in the array."
      ],
      "metadata": {
        "id": "aglvZRlbwJMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.doesnt_match(['shiva', 'sati', \"krittika\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "AWcug4_pn0Kb",
        "outputId": "02a2907d-471a-449e-97d3-e311624e82b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'shiva'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.wv.similarity('first word', 'second word')\n",
        "\n",
        "\n",
        "This method allows to find cosine similarity between two words. Higher it is closer to one, the more similar the words are."
      ],
      "metadata": {
        "id": "m83KFyTQwbv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity(\"krittika\",\"sati\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec1XzzdywOYm",
        "outputId": "050aa0b6-0287-4955-d843-0175cb363766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.978521"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity(\"shiva\",\"sati\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVslwxzLwqcI",
        "outputId": "c987bffe-93e7-4179-a583-0db4016b1803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9506833"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity(\"krittika\",\"warrior\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX3DiudLGM4f",
        "outputId": "0f222fce-567c-40fd-a065-36803a19815b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49806416"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similarity(\"parvateshwar\",\"warrior\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWko7jLSGg7q",
        "outputId": "96fe710b-ad2e-48de-a774-7682109890e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4553571"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.wv['<word>']:\n",
        "\n",
        "Displays the vector representation of a word that exists in the vocabulary."
      ],
      "metadata": {
        "id": "2rQSmlc8xROz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"shiva\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-dVmfvWw34f",
        "outputId": "44e54725-dea1-4f7f-ee50-f3432fa847fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00543561, -0.23771565,  0.9131056 ,  0.31328544, -0.4621426 ,\n",
              "       -0.6545937 ,  0.08630609,  0.49457797, -0.5719148 , -0.5421846 ,\n",
              "        0.35363135, -0.4895273 , -0.1379944 ,  0.30238163, -0.08937825,\n",
              "       -0.25313798,  0.40557015, -0.4270343 , -0.14119995, -0.8741759 ,\n",
              "        0.877691  ,  0.8957698 ,  0.68501717, -0.11159179,  0.31111106,\n",
              "        0.09970777, -0.35146347,  0.02964295, -0.16365702,  0.04136806,\n",
              "        0.08374083,  0.19053611, -0.05081322, -0.09916646, -0.2665848 ,\n",
              "        0.9192197 ,  0.2264377 , -0.49741697, -0.43907112, -1.1605176 ,\n",
              "       -0.09629039, -0.578658  , -0.512166  , -0.09168068,  0.33681706,\n",
              "        0.21794127, -0.4603607 ,  0.6652997 ,  0.3787522 , -0.05612567,\n",
              "        0.14346245, -0.14787324,  0.19197871, -0.57200986, -0.42425135,\n",
              "        0.23468103,  0.05179806,  0.27557212, -0.02733316,  0.3486072 ,\n",
              "       -0.3917228 , -0.11519313, -0.29998434, -0.5995471 , -0.46796036,\n",
              "        0.51135015, -0.27743217,  0.6505596 , -0.5845145 ,  0.3549786 ,\n",
              "       -0.26573974,  0.6877654 , -0.19192186,  0.07249457,  0.4839557 ,\n",
              "        0.2671566 ,  0.1409246 ,  0.14056773, -0.31347114,  0.3785159 ,\n",
              "       -0.32375255,  0.5867015 ,  1.0050665 ,  0.49162084, -0.73291796,\n",
              "       -0.46643883,  0.5573068 , -0.30723962,  0.3912096 ,  1.0314028 ,\n",
              "        0.96638167, -0.22514042,  0.09361105,  0.22218668,  0.6267625 ,\n",
              "        0.6512998 ,  0.64336956, -0.5106561 , -0.03887875,  0.19707912],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv[\"shiva\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rah_MU-lxXXd",
        "outputId": "5fe00fe5-d9cf-4c8e-b378-fc3b290bdbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQHExtOyxa-7",
        "outputId": "3bbd8563-0bb5-4a0f-c37c-aff24477352f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKFafM16xh9L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}